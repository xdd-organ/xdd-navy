<?xml version="1.0" encoding="UTF-8"?>
<!-- - - Licensed under the Apache License, Version 2.0 (the "License"); 
	- you may not use this file except in compliance with the License. - You 
	may obtain a copy of the License at - - http://www.apache.org/licenses/LICENSE-2.0 
	- - Unless required by applicable law or agreed to in writing, software - 
	distributed under the License is distributed on an "AS IS" BASIS, - WITHOUT 
	WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. - See the 
	License for the specific language governing permissions and - limitations 
	under the License. -->
<!DOCTYPE mycat:rule SYSTEM "rule.dtd">
<!-- 定义了我们对表进行拆分所涉及到的规则定义。
		我们可以灵活的对表使用不同的分片算法，或者对表使用相同的算法但具体的参数不同。
		这个文件里面主要有tableRule和function这两个标签。
		在具体使用过程中可以按照需求添加tableRule和function。
-->
<mycat:rule xmlns:mycat="http://io.mycat/">
	<!-- tableRule定义的表规则
		name:属性指定唯一的名字，用于标识不同的表规则。
	-->
	<tableRule name="rule1">
		<!-- rule定对物理表中的哪一列进行拆分和使用什么路由算法。
			columns:指定要拆分的列名字。
			algorithm:使用function标签中的name属性。
						连接表规则和具体路由算法。当然，多个表规则可以连接到同一个路由算法上。
						table标签内使用。让逻辑表使用这个规则进行分片。
		-->
		<rule>
			<columns>id</columns>
			<algorithm>func1</algorithm>
		</rule>
	</tableRule>

	<tableRule name="rule2">
		<rule>
			<columns>user_id</columns>
			<algorithm>func1</algorithm>
		</rule>
	</tableRule>

	<tableRule name="sharding-by-intfile">
		<rule>
			<columns>sharding_id</columns>
			<algorithm>hash-int</algorithm>
		</rule>
	</tableRule>
	<tableRule name="auto-sharding-long">
		<rule>
			<columns>id</columns>
			<algorithm>rang-long</algorithm>
		</rule>
	</tableRule>
	<tableRule name="mod-long">
		<rule>
			<columns>id</columns>
			<algorithm>mod-long</algorithm>
		</rule>
	</tableRule>
	<tableRule name="sharding-by-murmur">
		<rule>
			<columns>id</columns>
			<algorithm>murmur</algorithm>
		</rule>
	</tableRule>
	<tableRule name="crc32slot">
		<rule>
			<columns>id</columns>
			<algorithm>crc32slot</algorithm>
		</rule>
	</tableRule>
	<tableRule name="sharding-by-month">
		<rule>
			<columns>create_time</columns>
			<algorithm>partbymonth</algorithm>
		</rule>
	</tableRule>
	<tableRule name="latest-month-calldate">
		<rule>
			<columns>calldate</columns>
			<algorithm>latestMonth</algorithm>
		</rule>
	</tableRule>
	
	<tableRule name="auto-sharding-rang-mod">
		<rule>
			<columns>id</columns>
			<algorithm>rang-mod</algorithm>
		</rule>
	</tableRule>
	
	<tableRule name="jch">
		<rule>
			<columns>id</columns>
			<algorithm>jump-consistent-hash</algorithm>
		</rule>
	</tableRule>

	<!-- function标签
		name:指定算法的名字。
		class:指定路由算法具体的类名字。
		标签property为具体算法需要用到的一些属性。路由算法的配置可以查看算法章节
	-->
	<function name="murmur" class="io.mycat.route.function.PartitionByMurmurHash">
		<property name="seed">0</property><!-- 默认是0 -->
		<property name="count">2</property><!-- 要分片的数据库节点数量，必须指定，否则没法分片 -->
		<property name="virtualBucketTimes">160</property><!-- 一个实际的数据库节点被映射为这么多虚拟节点，默认是160倍，也就是虚拟节点数是物理节点数的160倍 -->
		<!-- <property name="weightMapFile">weightMapFile</property> 节点的权重，没有指定权重的节点默认是1。以properties文件的格式填写，以从0开始到count-1的整数值也就是节点索引为key，以节点权重值为值。所有权重值必须是正整数，否则以1代替 -->
		<!-- <property name="bucketMapPath">/etc/mycat/bucketMapPath</property> 
			用于测试时观察各物理节点与虚拟节点的分布情况，如果指定了这个属性，会把虚拟节点的murmur hash值与物理节点的映射按行输出到这个文件，没有默认值，如果不指定，就不会输出任何东西 -->
	</function>

	<function name="crc32slot"
			  class="io.mycat.route.function.PartitionByCRC32PreSlot">
		<property name="count">2</property><!-- 要分片的数据库节点数量，必须指定，否则没法分片 -->
	</function>
	<function name="hash-int"
		class="io.mycat.route.function.PartitionByFileMap">
		<property name="mapFile">partition-hash-int.txt</property>
	</function>
	<function name="rang-long"
		class="io.mycat.route.function.AutoPartitionByLong">
		<property name="mapFile">autopartition-long.txt</property>
	</function>
	<function name="mod-long" class="io.mycat.route.function.PartitionByMod">
		<!-- how many data nodes -->
		<property name="count">3</property>
	</function>

	<function name="func1" class="io.mycat.route.function.PartitionByLong">
		<property name="partitionCount">8</property>
		<property name="partitionLength">128</property>
	</function>
	<function name="latestMonth"
		class="io.mycat.route.function.LatestMonthPartion">
		<property name="splitOneDay">24</property>
	</function>
	<function name="partbymonth"
		class="io.mycat.route.function.PartitionByMonth">
		<property name="dateFormat">yyyy-MM-dd</property>
		<property name="sBeginDate">2015-01-01</property>
	</function>
	
	<function name="rang-mod" class="io.mycat.route.function.PartitionByRangeMod">
        	<property name="mapFile">partition-range-mod.txt</property>
	</function>

	<function name="jump-consistent-hash" class="io.mycat.route.function.PartitionByJumpConsistentHash">
		<property name="totalBuckets">3</property>
	</function>

	<!-- 分片规则：
		1、分片枚举算法
		通过在配置文件中配置可能的枚举id，自己配置分片，本规则适用于特定的场景，
		比如有些业务需要按照省份或区县来做保存，而全国省份区县固定的，这类业务使用本条规则，配置如下：
		例如：
		<tableRule name="sharding-by-intfile">
			<rule>
				<columns>user_id</columns> ## columns 标识将要分片的表字段
				<algorithm>hash-int</algorithm> ## algorithm 分片函数
			</rule>
		</tableRule>

		<function name="hash-int" class="org.opencloudb.route.function.PartitionByFileMap">
			<property name="mapFile">partition-hash-int.txt</property> ## mapFile标识配置文件名称
			<property name="type">0</property> ## type默认值为0，0表示Integer，非零表示String
			<property name="defaultNode">0</property> ## 默认节点:小于0表示不设置默认节点，大于等于0表示设置默认节点
		</function>

		文件partition-hash-int.txt配置(内容)：
		10000=0  ## 前面是值，后面是节点标识(当user_id = 10000，该数据会存储到指定的dataNode逻辑库)
		10010=1
		DEFAULT_NODE=1  ## 默认节点

		注意：
			defaultNode 默认节点:小于0表示不设置默认节点，大于等于0表示设置默认节点
			默认节点的作用：枚举分片时，如果碰到不识别的枚举值，就让它路由到默认节点
			如果不配置默认节点（defaultNode值小于0表示不配置默认节点），碰到* 不识别的枚举值就会报错，
			like this：can’t find datanode for sharding column:column_name val:ffffffff

		2、固定分片hash算法
		本条规则类似于十进制的求模运算，区别在于是二进制的操作,是取id的二进制低10位，即id二进制&1111111111，
		此算法的优点在于如果按照10进制取模运算，在连续插入1-10时候1-10会被分到1-10个分片，
		增大了插入的事务控制难度，而此算法根据二进制则可能会分到连续的分片，减少插入事务事务控制难度。

		<tableRule name="rule1">
			<rule>
				<columns>user_id</columns> ## columns 标识将要分片的表字段
				<algorithm>func1</algorithm> ## algorithm 分片函数
			</rule>
		</tableRule>
		<function name="func1" class="org.opencloudb.route.function.PartitionByLong">
			<property name="partitionCount">2,1</property> ## partitionCount 分片个数列表
			<property name="partitionLength">256,512</property> ## partitionLength 分片范围列表，
																	分区长度:默认为最大2^n=1024 ,即最大支持1024分区
		</function>

		注意：
		约束:partitionCount,partitionLength两个数组的长度必须是一致的。
			*重要* 1024 = sum((count[i]*length[i]))。count和length两个向量的点积恒等于1024
		上例解释：
			本例的分区策略：希望将数据水平分成3份，前两份各占25%，第三份占50%。
			// |<———————————————1024———————————>|
			// |<——256—>|<——256—>|<————512————->|
			// | partition0 | partition1 | partition2 |
			// |共2份,故count[0]=2 |共1份，故count[1]=1 |
			int[] count = new int[] { 2, 1 };
			int[] length = new int[] { 256, 512 };
			PartitionUtil pu = new P
			artitionUtil(count, length);


		例如：如果需要平均分配设置：平均分为4分片，partitionCount*partitionLength=1024
		<function name="func1" class="org.opencloudb.route.function.PartitionByLong">
			<property name="partitionCount">4</property>
			<property name="partitionLength">256</property>
		</function>

		3、范围约定算法
		此分片适用于，提前规划好分片字段某个范围属于哪个分片
		<tableRule name="auto-sharding-long">
			<rule>
				<columns>user_id</columns> ## columns 标识将要分片的表字段
				<algorithm>rang-long</algorithm> ## algorithm 分片函数
			</rule>
		</tableRule>
		<function name="rang-long" class="org.opencloudb.route.function.AutoPartitionByLong">
			<property name="mapFile">autopartition-long.txt</property> ## mapFile标识配置文件名称
			<property name="defaultNode">0</property> ## defaultNode 超过范围后的默认节点
		</function>

		文件autopartition-long.txt配置(内容)：
		0-10000000=0    	## 前面是范围，后面是节点标识(当在该范围，该数据会存储到指定的逻辑库，超过范围会存储在默认节点)
		10000001-20000000=1

		4、取模算法
		此规则为对分片字段求摸运算
		<tableRule name="mod-long">
			<rule>
				<columns>user_id</columns> ## columns 标识将要分片的表字段
				<algorithm>mod-long</algorithm> ## algorithm 分片函数
			</rule>
		</tableRule>
		<function name="mod-long" class="org.opencloudb.route.function.PartitionByMod">
			<property name="count">3</property> ## how many data nodes
		</function>

		注意：此种配置非常明确即根据id进行十进制求模预算，相比固定分片hash，
				此种在批量插入时可能存在批量插入单事务插入多数据分片，增大事务一致性难度

		5、按日期（天）分片
		<tableRule name="sharding-by-date">
			<rule>
				<columns>create_time</columns> ## columns 标识将要分片的表字段
				<algorithm>sharding-by-date</algorithm> ## algorithm 分片函数
			</rule>
		</tableRule>
		<function name="sharding-by-date" class="org.opencloudb.route.function.PartitionByDate">
			<property name="dateFormat">yyyy-MM-dd</property> ## dateFormat 日期格式
			<property name="sBeginDate">2014-01-01</property> ## sBeginDate 开始日期
			<property name="sEndDate">2014-01-02</property> ## sEndDate 结束日期
			<property name="sPartionDay">10</property> ## sPartionDay 分区天数，即默认从开始日期算起，分隔10天一个分区
		</function>

		注意：如果配置了sEndDate则代表数据达到了这个日期的分片后后循环从开始分片插入
				Assert.assertEquals(true, 0 == partition.calculate(“2014-01-01”));
				Assert.assertEquals(true, 0 == partition.calculate(“2014-01-10”));
				Assert.assertEquals(true, 1 == partition.calculate(“2014-01-11”));
				Assert.assertEquals(true, 12 == partition.calculate(“2014-05-01”));

		6、取模范围约束算法
		<tableRule name="sharding-by-pattern">
			<rule>
				<columns>user_id</columns>
				<algorithm>sharding-by-pattern</algorithm>
			</rule>
		</tableRule>
		<function name="sharding-by-pattern" class="org.opencloudb.route.function.PartitionByPattern">
			<property name="patternValue">256</property> ## patternValue即求模基数
			<property name="defaultNode">2</property> ## defaoultNode 默认节点，如果配置了默认，则不会按照求模运算
			<property name="mapFile">partition-pattern.txt</property>
		</function>

		文件partition-pattern.txt配置(内容)：
		# id partition range start-end ,data node index
		###### first host configuration
		1-32=0		1-32 即代表id%256后分布的范围，如果在1-32则在分区1，其他类推，如果id非数据，则会分配在defaoultNode 默认节点
		33-64=1
		65-96=2
		97-128=3
		######## second host configuration
		129-160=4
		161-192=5
		193-224=6
		225-256=7
		0-0=7

		注意：
			String idVal = “0”;
			Assert.assertEquals(true, 7 == autoPartition.calculate(idVal));
			idVal = “45a”;
			Assert.assertEquals(true, 2 == autoPartition.calculate(idVal));


	-->
</mycat:rule>
























